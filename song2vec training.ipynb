{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "131072"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import gensim\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "csv.field_size_limit(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create iterator for corpus training\n",
    "# from gensim.test.utils import datapath\n",
    "# from gensim import utils\n",
    "\n",
    "# class MyCorpus(object):\n",
    "#     \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         corpus_path = datapath('lee_background.cor')\n",
    "#         for line in open(corpus_path):\n",
    "#             # assume there's one document per line, tokens separated by whitespace\n",
    "#             yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Read in tracks...\nNumber of tracks: 19817445\n"
    }
   ],
   "source": [
    "print('Read in tracks...')\n",
    "tracks = {}\n",
    "with open('tracks.csv', \"r\", encoding='utf-8') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=';')\n",
    "    for row in spamreader:\n",
    "        columns = str(row)[2:-2].split(';')\n",
    "        tracks[columns[0]] = [columns[1] + ' - ' +\n",
    "                              columns[2], columns[3]] # title - artist, url\n",
    "print(f'Number of tracks: {len(tracks)}')\n",
    "\n",
    "# print('Read in playlists...')\n",
    "# playlists = []\n",
    "# with open('playlists.csv', 'r', encoding='utf-8') as csvfile:\n",
    "#     spamreader = csv.reader(csvfile, delimiter=';')\n",
    "#     for row in spamreader:\n",
    "#         columns = str(row)[2:-2].split(';')\n",
    "#         # if len(columns) < 1000: #limit length of playlists?\n",
    "#         playlist = []\n",
    "#         for column in columns[2:]:\n",
    "#             playlist.append(column)\n",
    "#         playlists.append(playlist)\n",
    "# print(f'Number of playlists: {len(playlists)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hyperparameters\n",
    "\n",
    "min_count = 10      # minimum number of occurences of a track in all playlists\n",
    "window = 2          # length of sequences\n",
    "embedding_dim = 100 # number of dimensions in hidden layer\n",
    "batch_words = 10000 # number of tracks to process in each batch\n",
    "# iter = 20           # number of iterations\n",
    "sg = 1              # skip-gram (1) or Continuous Bag Of Words (0)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "valid_examples = [\n",
    "    '2NMgVh5qaPprKTEzFe3501', # The Police - Roxanne\n",
    "    '3Ti0GdlrotgwsAVBBugv0I', # A Tribe Called Quest - Can I Kick It?\n",
    "    '0nyrltZrQGAJMBZc1bYvuQ', # James Brown - Get Up Offa That Thing\n",
    "    '4hy4fb5D1KL50b3sng9cjw', # Nirvana - Smells Like Teen Spirit\n",
    "    '1P49MJhU5vzttesFxw3dOM', # Bob Marley & The Wailers - Three Little Birds\n",
    "    '76GlO5H5RT6g7y0gev86Nk', # The Cure - Just Like Heaven\n",
    "    '40tAOP3DPqmVD6L1h45Jp6', # Frank Sinatra - My Way\n",
    "    '4IMvgp0WZqr9mRqpEvDKxI', # The Clash - Rock the Casbah\n",
    "    '1iDcKYNvo6gglrOG6lvnHL', # The Rolling Stones - Sympathy For The Devil\n",
    "    '5uvosCdMlFdTXhoazkTI5R', # The Doors - Light My Fire\n",
    "    '15JINEqzVMv3SvJTAXAKED', # Eminem - Love The Way You Lie\n",
    "    '69kOkLUCkxIZYexIgSG8rq', # Daft Punk - Get Lucky\n",
    "    '6oVY50pmdXqLNVeK8bzomn', # John Coltrane - My Favorite Things\n",
    "    '6ui6l3ZNvlrGQZArwo8195', # Sex Pistols - God Save The Queen\n",
    "    '0YammaEkYSeo9vQYZ1OwS6', # David Guetta - Say My Name\n",
    "    '4SHZsQIdS2N1E5yqvoXF8o'  # Andy Williams - Can't Take My Eyes Off You\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class logger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        print('Starting...')\n",
    "        self.epoch = 0\n",
    "        self.loss = 0\n",
    "\n",
    "    def on_train_begin(self, model):\n",
    "        self.start = time.time()\n",
    "        print(f'starting training epoch {self.epoch}')\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        elapsed = time.time() - self.start\n",
    "        print('#{}'.format(self.epoch), 'loss =',\n",
    "              (model.get_latest_training_loss() - self.loss) / batch_words,\n",
    "              'elapsed time =', elapsed // 60, 'minutes', elapsed % 60, 'seconds')\n",
    "        self.epoch += 1\n",
    "        self.loss = model.get_latest_training_loss()\n",
    "        print('Saving model...')\n",
    "        model.save('word2vec.model')\n",
    "        # _model = gensim.models.Word2Vec.load('word2vec.model')\n",
    "        # for track in valid_examples:\n",
    "        #     similar = _model.wv.most_similar(positive=[track], topn=8)\n",
    "        #     most_similar = ''\n",
    "        #     for i in range(0, 8):\n",
    "        #         most_similar = most_similar + '%s (%.2f)' % (tracks[similar[i][0]][0], similar[i][1]) + ', '\n",
    "        #     print('  %s -> %s' % (tracks[track][0], most_similar))\n",
    "        # print()\n",
    "        # del _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Starting...\nstarting training epoch 0\n#0 loss = 8115.2232 elapsed time = 33.0 minutes 5.925987005233765 seconds\nSaving model...\n#1 loss = 2720.6224 elapsed time = 71.0 minutes 27.31136202812195 seconds\nSaving model...\n#2 loss = 2585.9272 elapsed time = 109.0 minutes 57.78689408302307 seconds\nSaving model...\n#3 loss = 0.0 elapsed time = 147.0 minutes 48.547168016433716 seconds\nSaving model...\n#4 loss = 0.0 elapsed time = 184.0 minutes 0.7114369869232178 seconds\nSaving model...\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6a2e607e2ab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# assert gensim.models.Word2Vec.FAST_VERSION > -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = gensim.models.Word2Vec(sentences=playlists, size=embedding_dim,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                callbacks=[logger()],workers=4)\n",
      "\u001b[0;32m~/.pyenv/versions/song-vect/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2VecTrainables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashfxn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhashfxn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         super(Word2Vec, self).__init__(\n\u001b[0m\u001b[1;32m    598\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/song-vect/lib/python3.8/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             self.train(\n\u001b[0m\u001b[1;32m    747\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/song-vect/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \"\"\"\n\u001b[0;32m--> 724\u001b[0;31m         return super(Word2Vec, self).train(\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/song-vect/lib/python3.8/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_training_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         return super(BaseWordEmbeddingsModel, self).train(\n\u001b[0m\u001b[1;32m   1064\u001b[0m             \u001b[0mdata_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/song-vect/lib/python3.8/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_iterable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[0m\u001b[1;32m    551\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n",
      "\u001b[0;32m~/.pyenv/versions/song-vect/lib/python3.8/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[0m\u001b[1;32m    487\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             report_delay=report_delay, is_corpus_file_mode=False)\n",
      "\u001b[0;32m~/.pyenv/versions/song-vect/lib/python3.8/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# assert gensim.models.Word2Vec.FAST_VERSION > -1\n",
    "model = gensim.models.Word2Vec(sentences=playlists, size=embedding_dim,\n",
    "                               min_count=min_count, window=window, iter=iter,\n",
    "                               batch_words=batch_words, compute_loss=True, sg=True,\n",
    "                               callbacks=[logger()],workers=4)\n",
    "print(model)\n",
    "\n",
    "# no multi:\n",
    "#start time 11:24\n",
    "# ep1 12:37\n",
    "\n",
    "# multi:\n",
    "#start time 12:59\n",
    "# ep 0 1:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a87813ffe34d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('song2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.wv.save_word2vec_format(fname='song2vec.bin',fvocab='songVocab.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Word2Vec(vocab=2924687, size=100, alpha=0.025)\n"
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec.load('word2vec.model')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The Police - Roxanne -> Europe - The Final Countdown (0.85), The Police - Can't Stand Losing You (0.83), The Police - Walking On The Moon - 2003 Stereo Remastered Version (0.83), Men At Work - Down Under (0.83), The Police - Roxanne (0.83), The Beatles Recovered Band - Help! (0.82), Elvis Presley - A Little Less Conversation - JXL Radio Edit Remix (0.82), Peter Gabriel - Sledgehammer - Live (0.82), \n  A Tribe Called Quest - Can I Kick It? -> A Tribe Called Quest - Electric Relaxation (0.84), A Tribe Called Quest - Bonita Applebum - includes 'Can I Kick It' Intro (0.83), The Pharcyde - Passin' Me By (0.83), The Pharcyde - Runnin' (0.83), Souls Of Mischief - 93 'Til Infinity (0.83), The Pharcyde - Runnin' (0.82), Pete Rock & C.L. Smooth - They Reminisce Over You (T.R.O.Y.) (0.81), A Tribe Called Quest - Scenario (0.81), \n  James Brown - Get Up Offa That Thing -> James Brown - Papa's Got A Brand New Bag (0.81), James Brown - Get Up (I Feel Like Being A) Sex Machine - Pt. 1 & 2 (0.80), James Brown - I Got You (I Feel Good) (0.78), James Brown - Get Up (I Feel Like Being A) Sex Machine (0.77), The O'Jays - Love Train (0.77), James Brown - Hot Pants (She Got To Use What She Got To Get What She Wants) (0.76), James Brown & The Famous Flames - I Got You (I Feel Good) (0.76), The Jackson 5 - ABC (0.75), \n  Nirvana - Smells Like Teen Spirit -> Nirvana - Come As You Are (0.87), Nirvana - Lithium (0.87), Nirvana - Smells Like Teen Spirit (0.82), Nirvana - In Bloom - Nevermind Version (0.82), Papa Roach - Last Resort (0.81), Bon Jovi - Keep The Faith (0.80), Nirvana - Heart-Shaped Box (0.80), AFI - Miss Murder - Edited Version (0.80), \n  Bob Marley & The Wailers - Three Little Birds -> Bob Marley & The Wailers - Buffalo Soldier (0.88), Bob Marley & The Wailers - One Love / People Get Ready (0.87), Bob Marley & The Wailers - Jamming (0.86), Bob Marley & The Wailers - Stir It Up - Original Album Version (0.83), Bob Marley & The Wailers - Is This Love (0.83), Bob Marley & The Wailers - No Woman, No Cry - Live At The Lyceum, London/1975 (0.83), Bob Marley & The Wailers - Jamming (0.83), Bob Marley & The Wailers - Waiting In Vain (0.82), \n  The Cure - Just like Heaven -> The Cure - Boys Don't Cry - Single Version (0.90), The Cure - Close to Me - 2006 Remaster (0.88), The Cure - Lovesong - 2010 Remaster (0.87), The Cure - Pictures of You - 2010 Remaster (0.84), The Cure - In Between Days - 2006 Remaster (0.84), The Cure - Friday I'm in Love (0.83), The Cure - All I Want (0.82), The Cure - A Letter to Elise (0.81), \n  Frank Sinatra - My Way -> Frank Sinatra - Theme From New York, New York (0.84), Frank Sinatra - I Get a Kick Out of You (0.84), Frank Sinatra - My Funny Valentine (0.83), Frank Sinatra - I've Got You Under My Skin - 2007 Remastered Version (0.83), Frank Sinatra - Just In Time - Alternate Version (0.83), Frank Sinatra - All of Me (0.83), Frank Sinatra - I've Got You Under My Skin - Remastered 1998 (0.82), Frank Sinatra - I'll Never Smile Again (0.82), \n  The Clash - Rock the Casbah -> Madness - Our House (0.83), The Police - Message In A Bottle (0.82), New Order - Blue Monday (0.81), Nena - 99 Luftballons (0.81), Bruce Springsteen - Born in the U.S.A. (0.81), The Clash - Train in Vain (Stand by Me) - Remastered (0.81), James Brown - Living In America (0.81), Adam & The Ants - Stand and Deliver (0.81), \n  The Rolling Stones - Sympathy For The Devil -> The Rolling Stones - Paint It, Black - (Original Single Mono Version) (0.86), The Rolling Stones - Gimme Shelter (0.84), The Rolling Stones - Start Me Up - Remastered (0.84), The Rolling Stones - Jumpin' Jack Flash - Mono Version (0.83), The Rolling Stones - Brown Sugar - 2009 Mix (0.82), The Rolling Stones - You Can't Always Get What You Want (0.82), The Rolling Stones - (I Can't Get No) Satisfaction - Mono Version (0.81), The Rolling Stones - Wild Horses - 2009 Mix (0.80), \n  The Doors - Light My Fire -> The Doors - Break on Through (To the Other Side) (0.92), The Doors - People Are Strange (0.88), The Doors - Riders on the Storm (0.87), The Doors - L.A. Woman (0.87), The Doors - Roadhouse Blues (0.87), The Doors - Touch Me (0.86), The Doors - Hello, I Love You (0.86), The Doors - Love Me Two Times (0.85), \n  Eminem - Love The Way You Lie -> Eminem - Not Afraid (0.85), Eminem - The Monster (0.84), Eminem - The Monster (0.82), Eminem - Space Bound (0.82), Eminem - Encore (0.79), Rihanna - Love The Way You Lie (Part II) - Pt. 2 (0.79), Eminem - River (0.78), Eminem - Headlights (0.78), \n  Daft Punk - Get Lucky (feat. Pharrell Williams & Nile Rodgers) -> Daft Punk - Get Lucky (feat. Pharrell Williams & Nile Rodgers) - Radio Edit (0.88), Daft Punk - Lose Yourself to Dance (feat. Pharrell Williams) (0.85), Daft Punk - One More Time (0.80), Daft Punk - Instant Crush (feat. Julian Casablancas) (0.79), Daft Punk - Give Life Back to Music (0.78), Daft Punk - Fragments of Time (feat. Todd Edwards) (0.77), Daft Punk - Harder, Better, Faster, Stronger (0.76), Daft Punk - Doin' it Right (feat. Panda Bear) (0.75), \n  John Coltrane - My Favorite Things -> Duke Ellington - Jeep's Blues (0.88), Dave Brubeck - Blue Rondo à la Turk (0.88), Duke Ellington - Haupe (0.87), John Coltrane Quartet - A Love Supreme Part I: Acknowledgement (0.87), Duke Ellington - Take The “A” Train (0.87), Benny Goodman - Ain't Misbehavin' (0.87), Charles Mingus - Moanin' (0.86), Dizzy Gillespie - A Night In Tunisia (0.86), \n  Sex Pistols - God Save the Queen -> Sex Pistols - Anarchy in the U.K. (0.89), Sex Pistols - Pretty Vacant (0.86), Sex Pistols - Holidays in the Sun (0.84), Sex Pistols - Bodies (0.82), The Stooges - Search and Destroy (0.82), Sex Pistols - Sub-Mission (0.81), Sex Pistols - Anarchy In the UK (0.80), Ramones - Rock 'N' Roll High School - Remastered (0.80), \n  David Guetta - Say My Name -> ALMA - Perfect (0.83), David Guetta - Say My Name (0.81), INNA - No Help (0.80), Karmen - Lock My Hips (0.79), Ava Max - Sweet but Psycho (0.79), David Guetta - Don't Leave Me Alone (feat. Anne-Marie) (0.78), Iuliana - Fire Flame (0.78), David Guetta - Say My Name (0.77), \n  Andy Williams - Can't Take My Eyes Off You -> Andy Williams - Can't Take My Eyes Off You (0.84), Dean Martin - Everybody Loves Somebody - Dream with Dean Version (0.84), Frank Sinatra - I ve Got You Under My Skin (0.84), The Kisslcats - Put Your Hand On My Shoulder (0.83), Frank Sinatra - The Best Is Yet To Come - 2008 Remastered (0.83), Frank Sinatra - My Funny Valentine (0.83), Frank Sinatra - The Way You Look Tonight - Remastered 2008 (0.82), Paul Anka - Save the Last Dance for Me (0.82), \n"
    }
   ],
   "source": [
    "for track in valid_examples:\n",
    "            similar = model.wv.most_similar(positive=[track], topn=8)\n",
    "            most_similar = ''\n",
    "            for i in range(0, 8):\n",
    "                most_similar = most_similar + '%s (%.2f)' % (tracks[similar[i][0]][0], similar[i][1]) + ', '\n",
    "            print('  %s -> %s' % (tracks[track][0], most_similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}